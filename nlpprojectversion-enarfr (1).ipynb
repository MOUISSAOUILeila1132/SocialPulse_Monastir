{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13290442,"sourceType":"datasetVersion","datasetId":8423275}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-03T09:31:36.462396Z","iopub.execute_input":"2025-12-03T09:31:36.462582Z","iopub.status.idle":"2025-12-03T09:31:37.831024Z","shell.execute_reply.started":"2025-12-03T09:31:36.462566Z","shell.execute_reply":"2025-12-03T09:31:37.830280Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/videotest1112/..          .mp4\n/kaggle/input/videotest1112/Wayne Rooney says Ruben Amorim and players must take responsibility for Man Utd form (1).mp4\n/kaggle/input/videotest1112/Hamas and Israel begin indirect talks to end devastating war in Gaza (1).mp4\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Step 1: FIXED Kaggle dependencies with proper numpy version\n!pip uninstall -y numpy transformers accelerate\n!pip install numpy==1.24.3\n!pip install transformers==4.30.0\n!pip install accelerate==0.20.3\n!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n!pip install opencv-python moviepy librosa spacy nltk\n!pip install speechrecognition pydub sumy textblob\n!pip install facenet-pytorch\n!pip install deep-translator\n!pip install arabic-reshaper\n!pip install python-bidi\n!pip install pyarabic\n\n# Download spaCy models\n!python -m spacy download en_core_web_sm -q\n!python -m spacy download fr_core_news_sm -q\n\nprint(\"✅ Kaggle dependencies installed successfully!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T09:33:03.577624Z","iopub.execute_input":"2025-12-03T09:33:03.577945Z","iopub.status.idle":"2025-12-03T09:37:43.710502Z","shell.execute_reply.started":"2025-12-03T09:33:03.577922Z","shell.execute_reply":"2025-12-03T09:37:43.709626Z"}},"outputs":[{"name":"stdout","text":"Found existing installation: numpy 1.26.4\nUninstalling numpy-1.26.4:\n  Successfully uninstalled numpy-1.26.4\nFound existing installation: transformers 4.53.3\nUninstalling transformers-4.53.3:\n  Successfully uninstalled transformers-4.53.3\nFound existing installation: accelerate 1.9.0\nUninstalling accelerate-1.9.0:\n  Successfully uninstalled accelerate-1.9.0\nCollecting numpy==1.24.3\n  Downloading numpy-1.24.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\nDownloading numpy-1.24.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m64.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m:01\u001b[0mm\n\u001b[?25hInstalling collected packages: numpy\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nkaggle-environments 1.18.0 requires transformers>=4.33.1, which is not installed.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\nsentence-transformers 4.1.0 requires transformers<5.0.0,>=4.41.0, which is not installed.\npeft 0.16.0 requires accelerate>=0.21.0, which is not installed.\npeft 0.16.0 requires transformers, which is not installed.\ngensim 4.3.3 requires scipy<1.14.0,>=1.7.0, but you have scipy 1.15.3 which is incompatible.\nmkl-umath 0.1.1 requires numpy<1.27.0,>=1.26.4, but you have numpy 1.24.3 which is incompatible.\nmkl-random 1.2.4 requires numpy<1.27.0,>=1.26.4, but you have numpy 1.24.3 which is incompatible.\nmkl-fft 1.3.8 requires numpy<1.27.0,>=1.26.4, but you have numpy 1.24.3 which is incompatible.\ndatasets 4.1.1 requires pyarrow>=21.0.0, but you have pyarrow 19.0.1 which is incompatible.\nwoodwork 0.31.0 requires numpy>=1.25.0, but you have numpy 1.24.3 which is incompatible.\nonnx 1.18.0 requires protobuf>=4.25.1, but you have protobuf 3.20.3 which is incompatible.\nfeaturetools 1.31.0 requires numpy>=1.25.0, but you have numpy 1.24.3 which is incompatible.\nbayesian-optimization 3.1.0 requires numpy>=1.25; python_full_version < \"3.13\", but you have numpy 1.24.3 which is incompatible.\nmne 1.10.1 requires numpy<3,>=1.25, but you have numpy 1.24.3 which is incompatible.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.24.3 which is incompatible.\ngoogle-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.40.3 which is incompatible.\ngoogle-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\ngoogle-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\ngoogle-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.5 which is incompatible.\ngoogle-colab 1.0.0 requires tornado==6.4.2, but you have tornado 6.5.2 which is incompatible.\njax 0.5.2 requires numpy>=1.25, but you have numpy 1.24.3 which is incompatible.\ndopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\nbigframes 2.12.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.1.0 which is incompatible.\nthinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.24.3 which is incompatible.\nopencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.24.3 which is incompatible.\ntreescope 0.1.9 requires numpy>=1.25.2, but you have numpy 1.24.3 which is incompatible.\nopencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.24.3 which is incompatible.\ngradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.0a1 which is incompatible.\nimbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.2 which is incompatible.\nalbumentations 2.0.8 requires numpy>=1.24.4, but you have numpy 1.24.3 which is incompatible.\npandas-gbq 0.29.2 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\nxarray-einstats 0.9.1 requires numpy>=1.25, but you have numpy 1.24.3 which is incompatible.\nxarray 2025.7.1 requires numpy>=1.26, but you have numpy 1.24.3 which is incompatible.\nopencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.24.3 which is incompatible.\nplotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\nalbucore 0.0.24 requires numpy>=1.24.4, but you have numpy 1.24.3 which is incompatible.\ntensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 1.24.3 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\njaxlib 0.5.1 requires numpy>=1.25, but you have numpy 1.24.3 which is incompatible.\numap-learn 0.5.9.post2 requires scikit-learn>=1.6, but you have scikit-learn 1.2.2 which is incompatible.\npymc 5.25.1 requires numpy>=1.25.0, but you have numpy 1.24.3 which is incompatible.\nmlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\nblosc2 3.6.1 requires numpy>=1.26, but you have numpy 1.24.3 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed numpy-1.24.3\nCollecting transformers==4.30.0\n  Downloading transformers-4.30.0-py3-none-any.whl.metadata (113 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.6/113.6 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.30.0) (3.19.1)\nCollecting huggingface-hub<1.0,>=0.14.1 (from transformers==4.30.0)\n  Downloading huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.30.0) (1.24.3)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.30.0) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.30.0) (6.0.3)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.30.0) (2025.9.18)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.30.0) (2.32.5)\nCollecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.30.0)\n  Downloading tokenizers-0.13.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\nRequirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.30.0) (0.5.3)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.30.0) (4.67.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.30.0) (2025.9.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.30.0) (4.15.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.30.0) (1.1.10)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.30.0) (3.4.3)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.30.0) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.30.0) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.30.0) (2025.8.3)\nDownloading transformers-4.30.0-py3-none-any.whl (7.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m566.1/566.1 kB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tokenizers-0.13.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m108.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: tokenizers, huggingface-hub, transformers\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.21.2\n    Uninstalling tokenizers-0.21.2:\n      Successfully uninstalled tokenizers-0.21.2\n  Attempting uninstall: huggingface-hub\n    Found existing installation: huggingface-hub 1.0.0rc2\n    Uninstalling huggingface-hub-1.0.0rc2:\n      Successfully uninstalled huggingface-hub-1.0.0rc2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npeft 0.16.0 requires accelerate>=0.21.0, which is not installed.\ndatasets 4.1.1 requires pyarrow>=21.0.0, but you have pyarrow 19.0.1 which is incompatible.\nkaggle-environments 1.18.0 requires transformers>=4.33.1, but you have transformers 4.30.0 which is incompatible.\nsentence-transformers 4.1.0 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.30.0 which is incompatible.\ngradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.0a1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed huggingface-hub-0.36.0 tokenizers-0.13.3 transformers-4.30.0\nCollecting accelerate==0.20.3\n  Downloading accelerate-0.20.3-py3-none-any.whl.metadata (17 kB)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate==0.20.3) (1.24.3)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate==0.20.3) (25.0)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate==0.20.3) (7.1.0)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate==0.20.3) (6.0.3)\nRequirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from accelerate==0.20.3) (2.6.0+cu124)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->accelerate==0.20.3) (3.19.1)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->accelerate==0.20.3) (4.15.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->accelerate==0.20.3) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->accelerate==0.20.3) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->accelerate==0.20.3) (2025.9.0)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.6.0->accelerate==0.20.3)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.6.0->accelerate==0.20.3)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.6.0->accelerate==0.20.3)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.6.0->accelerate==0.20.3)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.6.0->accelerate==0.20.3)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.6.0->accelerate==0.20.3)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.6.0->accelerate==0.20.3)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.6.0->accelerate==0.20.3)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.6.0->accelerate==0.20.3)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->accelerate==0.20.3) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->accelerate==0.20.3) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->accelerate==0.20.3) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.6.0->accelerate==0.20.3)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->accelerate==0.20.3) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->accelerate==0.20.3) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.6.0->accelerate==0.20.3) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.6.0->accelerate==0.20.3) (3.0.2)\nDownloading accelerate-0.20.3-py3-none-any.whl (227 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.6/227.6 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m101.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m75.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m55.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m66.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, accelerate\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\npeft 0.16.0 requires accelerate>=0.21.0, but you have accelerate 0.20.3 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed accelerate-0.20.3 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\nLooking in indexes: https://download.pytorch.org/whl/cu118\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\nRequirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.19.1)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.15.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.9.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.24.3)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.12.0.88)\nRequirement already satisfied: moviepy in /usr/local/lib/python3.11/dist-packages (1.0.3)\nRequirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (0.11.0)\nRequirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.8.7)\nRequirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\nCollecting numpy<2.3.0,>=2 (from opencv-python)\n  Downloading numpy-2.2.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.11/dist-packages (from moviepy) (4.4.2)\nRequirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.11/dist-packages (from moviepy) (4.67.1)\nRequirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.11/dist-packages (from moviepy) (2.32.5)\nRequirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.11/dist-packages (from moviepy) (0.1.12)\nRequirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.11/dist-packages (from moviepy) (2.37.0)\nRequirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from moviepy) (0.6.0)\nRequirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa) (3.0.1)\nRequirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.60.0)\nRequirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.15.3)\nRequirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.2.2)\nRequirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.5.2)\nRequirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.13.1)\nRequirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.8.2)\nRequirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.5.0.post1)\nRequirement already satisfied: typing_extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.15.0)\nRequirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.4)\nRequirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.1.1)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.13)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.10)\nRequirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.3.6)\nRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\nRequirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\nRequirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.16.0)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.12.0a1)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.1.6)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.2.0)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (25.0)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\nRequirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.3.0)\nRequirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2025.9.18)\nRequirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.11/dist-packages (from imageio<3.0,>=2.5->moviepy) (11.3.0)\nRequirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\nRequirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n  Downloading numpy-2.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.9/60.9 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (4.4.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\nRequirement already satisfied: pydantic-core==2.37.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.37.2)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.4.3)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2025.8.3)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\nRequirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->librosa) (2.0.0)\nRequirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\nRequirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\nRequirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (14.1.0)\nRequirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.1)\nRequirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.3.0.post1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy) (3.0.2)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.23)\nRequirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (4.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.2)\nRequirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\nDownloading numpy-2.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.5/19.5 MB\u001b[0m \u001b[31m88.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: numpy\n  Attempting uninstall: numpy\n    Found existing installation: numpy 1.24.3\n    Uninstalling numpy-1.24.3:\n      Successfully uninstalled numpy-1.24.3\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ngensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.0.2 which is incompatible.\ngensim 4.3.3 requires scipy<1.14.0,>=1.7.0, but you have scipy 1.15.3 which is incompatible.\nmkl-umath 0.1.1 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.0.2 which is incompatible.\nmkl-random 1.2.4 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.0.2 which is incompatible.\nmkl-fft 1.3.8 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.0.2 which is incompatible.\ndatasets 4.1.1 requires pyarrow>=21.0.0, but you have pyarrow 19.0.1 which is incompatible.\nonnx 1.18.0 requires protobuf>=4.25.1, but you have protobuf 3.20.3 which is incompatible.\nkaggle-environments 1.18.0 requires transformers>=4.33.1, but you have transformers 4.30.0 which is incompatible.\ngoogle-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.40.3 which is incompatible.\ngoogle-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\ngoogle-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\ngoogle-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.5 which is incompatible.\ngoogle-colab 1.0.0 requires tornado==6.4.2, but you have tornado 6.5.2 which is incompatible.\ndopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\nbigframes 2.12.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.1.0 which is incompatible.\nsentence-transformers 4.1.0 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.30.0 which is incompatible.\npeft 0.16.0 requires accelerate>=0.21.0, but you have accelerate 0.20.3 which is incompatible.\ngradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.0a1 which is incompatible.\nimbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.2 which is incompatible.\npandas-gbq 0.29.2 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\nplotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\numap-learn 0.5.9.post2 requires scikit-learn>=1.6, but you have scikit-learn 1.2.2 which is incompatible.\nmlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed numpy-2.0.2\nCollecting speechrecognition\n  Downloading speechrecognition-3.14.4-py3-none-any.whl.metadata (30 kB)\nRequirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (0.25.1)\nCollecting sumy\n  Downloading sumy-0.11.0-py2.py3-none-any.whl.metadata (7.5 kB)\nRequirement already satisfied: textblob in /usr/local/lib/python3.11/dist-packages (0.19.0)\nRequirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from speechrecognition) (4.15.0)\nCollecting docopt<0.7,>=0.6.1 (from sumy)\n  Downloading docopt-0.6.2.tar.gz (25 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nCollecting breadability>=0.1.20 (from sumy)\n  Downloading breadability-0.1.20.tar.gz (32 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: requests>=2.7.0 in /usr/local/lib/python3.11/dist-packages (from sumy) (2.32.5)\nCollecting pycountry>=18.2.23 (from sumy)\n  Downloading pycountry-24.6.1-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: nltk>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from sumy) (3.9.1)\nRequirement already satisfied: chardet in /usr/local/lib/python3.11/dist-packages (from breadability>=0.1.20->sumy) (5.2.0)\nRequirement already satisfied: lxml>=2.0 in /usr/local/lib/python3.11/dist-packages (from breadability>=0.1.20->sumy) (5.4.0)\nRequirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>=3.0.2->sumy) (8.3.0)\nRequirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>=3.0.2->sumy) (1.5.2)\nRequirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>=3.0.2->sumy) (2025.9.18)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk>=3.0.2->sumy) (4.67.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.7.0->sumy) (3.4.3)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.7.0->sumy) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.7.0->sumy) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.7.0->sumy) (2025.8.3)\nDownloading speechrecognition-3.14.4-py3-none-any.whl (32.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.9/32.9 MB\u001b[0m \u001b[31m67.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading sumy-0.11.0-py2.py3-none-any.whl (97 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.3/97.3 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pycountry-24.6.1-py3-none-any.whl (6.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m123.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: breadability, docopt\n  Building wheel for breadability (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for breadability: filename=breadability-0.1.20-py2.py3-none-any.whl size=21693 sha256=6785e2589bae7f95506725eb46c17babe11b8ab3c027d81ed70dea5b073b289f\n  Stored in directory: /root/.cache/pip/wheels/4d/57/58/7e3d7fedf51fe248b7fcee3df6945ae28638e22cddf01eb92b\n  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=49cd8217e71372eb09419d0cfc92e29845bd216ba1b104fad673c25c4c35e225\n  Stored in directory: /root/.cache/pip/wheels/1a/b0/8c/4b75c4116c31f83c8f9f047231251e13cc74481cca4a78a9ce\nSuccessfully built breadability docopt\nInstalling collected packages: docopt, speechrecognition, pycountry, breadability, sumy\nSuccessfully installed breadability-0.1.20 docopt-0.6.2 pycountry-24.6.1 speechrecognition-3.14.4 sumy-0.11.0\nCollecting facenet-pytorch\n  Downloading facenet_pytorch-2.6.0-py3-none-any.whl.metadata (12 kB)\nCollecting numpy<2.0.0,>=1.24.0 (from facenet-pytorch)\n  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting Pillow<10.3.0,>=10.2.0 (from facenet-pytorch)\n  Downloading pillow-10.2.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.7 kB)\nRequirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from facenet-pytorch) (2.32.5)\nCollecting torch<2.3.0,>=2.2.0 (from facenet-pytorch)\n  Downloading torch-2.2.2-cp311-cp311-manylinux1_x86_64.whl.metadata (25 kB)\nCollecting torchvision<0.18.0,>=0.17.0 (from facenet-pytorch)\n  Downloading torchvision-0.17.2-cp311-cp311-manylinux1_x86_64.whl.metadata (6.6 kB)\nRequirement already satisfied: tqdm<5.0.0,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from facenet-pytorch) (4.67.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch) (3.4.3)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch) (2025.8.3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (3.19.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (4.15.0)\nRequirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (1.13.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (2025.9.0)\nCollecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch<2.3.0,>=2.2.0->facenet-pytorch)\n  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch<2.3.0,>=2.2.0->facenet-pytorch)\n  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch<2.3.0,>=2.2.0->facenet-pytorch)\n  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch<2.3.0,>=2.2.0->facenet-pytorch)\n  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.1.3.1 (from torch<2.3.0,>=2.2.0->facenet-pytorch)\n  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.0.2.54 (from torch<2.3.0,>=2.2.0->facenet-pytorch)\n  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.2.106 (from torch<2.3.0,>=2.2.0->facenet-pytorch)\n  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch<2.3.0,>=2.2.0->facenet-pytorch)\n  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch<2.3.0,>=2.2.0->facenet-pytorch)\n  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-nccl-cu12==2.19.3 (from torch<2.3.0,>=2.2.0->facenet-pytorch)\n  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-nvtx-cu12==12.1.105 (from torch<2.3.0,>=2.2.0->facenet-pytorch)\n  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\nCollecting triton==2.2.0 (from torch<2.3.0,>=2.2.0->facenet-pytorch)\n  Downloading triton-2.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\nRequirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch<2.3.0,>=2.2.0->facenet-pytorch) (12.4.127)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<2.3.0,>=2.2.0->facenet-pytorch) (3.0.2)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch<2.3.0,>=2.2.0->facenet-pytorch) (1.3.0)\nDownloading facenet_pytorch-2.6.0-py3-none-any.whl (1.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m90.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading pillow-10.2.0-cp311-cp311-manylinux_2_28_x86_64.whl (4.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m109.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading torch-2.2.2-cp311-cp311-manylinux1_x86_64.whl (755.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.6/755.6 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m983.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading triton-2.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading torchvision-0.17.2-cp311-cp311-manylinux1_x86_64.whl (6.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m82.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: triton, Pillow, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch, torchvision, facenet-pytorch\n  Attempting uninstall: triton\n    Found existing installation: triton 3.2.0\n    Uninstalling triton-3.2.0:\n      Successfully uninstalled triton-3.2.0\n  Attempting uninstall: Pillow\n    Found existing installation: pillow 11.3.0\n    Uninstalling pillow-11.3.0:\n      Successfully uninstalled pillow-11.3.0\n  Attempting uninstall: nvidia-nvtx-cu12\n    Found existing installation: nvidia-nvtx-cu12 12.4.127\n    Uninstalling nvidia-nvtx-cu12-12.4.127:\n      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n  Attempting uninstall: nvidia-nccl-cu12\n    Found existing installation: nvidia-nccl-cu12 2.21.5\n    Uninstalling nvidia-nccl-cu12-2.21.5:\n      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.3.1.170\n    Uninstalling nvidia-cusparse-cu12-12.3.1.170:\n      Successfully uninstalled nvidia-cusparse-cu12-12.3.1.170\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.5.147\n    Uninstalling nvidia-curand-cu12-10.3.5.147:\n      Successfully uninstalled nvidia-curand-cu12-10.3.5.147\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.1.3\n    Uninstalling nvidia-cufft-cu12-11.2.1.3:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.1.3\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.4.127\n    Uninstalling nvidia-cuda-runtime-cu12-12.4.127:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.4.127\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.4.127\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.4.127:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.4.127\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.4.127\n    Uninstalling nvidia-cuda-cupti-cu12-12.4.127:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.4.127\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.4.5.8\n    Uninstalling nvidia-cublas-cu12-12.4.5.8:\n      Successfully uninstalled nvidia-cublas-cu12-12.4.5.8\n  Attempting uninstall: numpy\n    Found existing installation: numpy 2.0.2\n    Uninstalling numpy-2.0.2:\n      Successfully uninstalled numpy-2.0.2\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.1.9\n    Uninstalling nvidia-cusolver-cu12-11.6.1.9:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.1.9\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.1.0.70\n    Uninstalling nvidia-cudnn-cu12-9.1.0.70:\n      Successfully uninstalled nvidia-cudnn-cu12-9.1.0.70\n  Attempting uninstall: torch\n    Found existing installation: torch 2.6.0+cu124\n    Uninstalling torch-2.6.0+cu124:\n      Successfully uninstalled torch-2.6.0+cu124\n  Attempting uninstall: torchvision\n    Found existing installation: torchvision 0.21.0+cu124\n    Uninstalling torchvision-0.21.0+cu124:\n      Successfully uninstalled torchvision-0.21.0+cu124\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ngensim 4.3.3 requires scipy<1.14.0,>=1.7.0, but you have scipy 1.15.3 which is incompatible.\ndatasets 4.1.1 requires pyarrow>=21.0.0, but you have pyarrow 19.0.1 which is incompatible.\nonnx 1.18.0 requires protobuf>=4.25.1, but you have protobuf 3.20.3 which is incompatible.\nkaggle-environments 1.18.0 requires transformers>=4.33.1, but you have transformers 4.30.0 which is incompatible.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\ngoogle-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.40.3 which is incompatible.\ngoogle-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\ngoogle-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\ngoogle-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.5 which is incompatible.\ngoogle-colab 1.0.0 requires tornado==6.4.2, but you have tornado 6.5.2 which is incompatible.\ndopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\nbigframes 2.12.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.1.0 which is incompatible.\nsentence-transformers 4.1.0 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.30.0 which is incompatible.\nthinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\nopencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\ntorchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.2.2 which is incompatible.\nopencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\npeft 0.16.0 requires accelerate>=0.21.0, but you have accelerate 0.20.3 which is incompatible.\ngradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.0a1 which is incompatible.\nimbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.2 which is incompatible.\npandas-gbq 0.29.2 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\nopencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\nplotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\numap-learn 0.5.9.post2 requires scikit-learn>=1.6, but you have scikit-learn 1.2.2 which is incompatible.\nmlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed Pillow-10.2.0 facenet-pytorch-2.6.0 numpy-1.26.4 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvtx-cu12-12.1.105 torch-2.2.2 torchvision-0.17.2 triton-2.2.0\nCollecting deep-translator\n  Downloading deep_translator-1.11.4-py3-none-any.whl.metadata (30 kB)\nRequirement already satisfied: beautifulsoup4<5.0.0,>=4.9.1 in /usr/local/lib/python3.11/dist-packages (from deep-translator) (4.13.4)\nRequirement already satisfied: requests<3.0.0,>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from deep-translator) (2.32.5)\nRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep-translator) (2.7)\nRequirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep-translator) (4.15.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.23.0->deep-translator) (3.4.3)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.23.0->deep-translator) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.23.0->deep-translator) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.23.0->deep-translator) (2025.8.3)\nDownloading deep_translator-1.11.4-py3-none-any.whl (42 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: deep-translator\nSuccessfully installed deep-translator-1.11.4\nCollecting arabic-reshaper\n  Downloading arabic_reshaper-3.0.0-py3-none-any.whl.metadata (12 kB)\nDownloading arabic_reshaper-3.0.0-py3-none-any.whl (20 kB)\nInstalling collected packages: arabic-reshaper\nSuccessfully installed arabic-reshaper-3.0.0\nRequirement already satisfied: python-bidi in /usr/local/lib/python3.11/dist-packages (0.6.6)\nRequirement already satisfied: pyarabic in /usr/local/lib/python3.11/dist-packages (0.6.15)\nRequirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from pyarabic) (1.17.0)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m92.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\nYou can now load the package via spacy.load('en_core_web_sm')\n\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\nIf you are in a Jupyter or Colab notebook, you may need to restart Python in\norder to load all the package's dependencies. You can do this by selecting the\n'Restart kernel' or 'Restart runtime' option.\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\nYou can now load the package via spacy.load('fr_core_news_sm')\n\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\nIf you are in a Jupyter or Colab notebook, you may need to restart Python in\norder to load all the package's dependencies. You can do this by selecting the\n'Restart kernel' or 'Restart runtime' option.\n✅ Kaggle dependencies installed successfully!\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Step 2: Import libraries with proper error handling\nimport sys\nimport subprocess\nimport importlib\n\ndef safe_import(module_name, install_name=None):\n    \"\"\"Safely import a module with installation fallback\"\"\"\n    if install_name is None:\n        install_name = module_name\n    \n    try:\n        module = importlib.import_module(module_name)\n        print(f\"✅ {module_name} imported successfully\")\n        return module\n    except ImportError:\n        print(f\"📦 Installing {install_name}...\")\n        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", install_name])\n        return importlib.import_module(module_name)\n\n# Import critical packages\nprint(\"🔄 Importing libraries...\")\nimport numpy as np\nprint(f\"✅ NumPy version: {np.__version__}\")\n\nimport cv2\nimport torch\nprint(f\"✅ PyTorch version: {torch.__version__}\")\n\n# Import transformers components safely\ntry:\n    from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification\n    print(\"✅ Transformers imported successfully\")\nexcept Exception as e:\n    print(f\"❌ Transformers import failed: {e}\")\n    # Try alternative import\n    try:\n        import transformers\n        print(\"✅ Transformers imported via alternative method\")\n    except Exception as e2:\n        print(f\"❌ Alternative import also failed: {e2}\")\n        raise e2\n\nimport speech_recognition as sr\nfrom moviepy.editor import VideoFileClip\nimport spacy\nfrom sumy.parsers.plaintext import PlaintextParser\nfrom sumy.nlp.tokenizers import Tokenizer\nfrom sumy.summarizers.lsa import LsaSummarizer\nimport librosa\nimport warnings\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom facenet_pytorch import MTCNN\nimport tempfile\nimport os\nimport json\nfrom deep_translator import GoogleTranslator\nimport arabic_reshaper\nfrom bidi.algorithm import get_display\nimport IPython.display as ipd\nfrom pathlib import Path\nwarnings.filterwarnings('ignore')\n\nprint(\"✅ All libraries imported successfully!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T09:39:01.545587Z","iopub.execute_input":"2025-12-03T09:39:01.546174Z","iopub.status.idle":"2025-12-03T09:39:04.772847Z","shell.execute_reply.started":"2025-12-03T09:39:01.546142Z","shell.execute_reply":"2025-12-03T09:39:04.772143Z"}},"outputs":[{"name":"stdout","text":"🔄 Importing libraries...\n✅ NumPy version: 1.26.4\n✅ PyTorch version: 2.6.0+cu124\n✅ Transformers imported successfully\n","output_type":"stream"},{"name":"stderr","text":"error: XDG_RUNTIME_DIR not set in the environment.\nALSA lib confmisc.c:855:(parse_card) cannot find card '0'\nALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_card_inum returned error: No such file or directory\nALSA lib confmisc.c:422:(snd_func_concat) error evaluating strings\nALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_concat returned error: No such file or directory\nALSA lib confmisc.c:1334:(snd_func_refer) error evaluating name\nALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\nALSA lib conf.c:5701:(snd_config_expand) Evaluate error: No such file or directory\nALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM default\nALSA lib confmisc.c:855:(parse_card) cannot find card '0'\nALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_card_inum returned error: No such file or directory\nALSA lib confmisc.c:422:(snd_func_concat) error evaluating strings\nALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_concat returned error: No such file or directory\nALSA lib confmisc.c:1334:(snd_func_refer) error evaluating name\nALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\nALSA lib conf.c:5701:(snd_config_expand) Evaluate error: No such file or directory\nALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM default\n","output_type":"stream"},{"name":"stdout","text":"✅ All libraries imported successfully!\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# Step 3: ULTRA-SIMPLE Video Analyzer (No transformers pipeline dependency)\nclass UltraSimpleVideoAnalyzer:\n    def __init__(self):\n        self.setup_ultra_simple_models()\n        \n    def setup_ultra_simple_models(self):\n        \"\"\"Setup models without using transformers pipeline\"\"\"\n        print(\"🔄 Setting up ultra-simple models...\")\n        \n        # Use OpenCV for face detection only\n        self.face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n        \n        # Speech recognition\n        self.recognizer = sr.Recognizer()\n        \n        # Simple emotion mapping (we'll use text-based analysis)\n        self.emotion_keywords = {\n            'happy': ['happy', 'joy', 'excited', 'good', 'great', 'wonderful', 'amazing'],\n            'sad': ['sad', 'unhappy', 'cry', 'bad', 'terrible', 'awful', 'depressed'],\n            'angry': ['angry', 'mad', 'frustrated', 'annoyed', 'upset'],\n            'neutral': ['ok', 'fine', 'normal', 'regular', 'usual']\n        }\n        \n        # Topic keywords\n        self.topic_keywords = {\n            'sports': ['sport', 'game', 'player', 'team', 'match', 'goal', 'win'],\n            'politics': ['government', 'president', 'minister', 'election', 'policy'],\n            'entertainment': ['movie', 'music', 'show', 'celebrity', 'film', 'song'],\n            'technology': ['computer', 'phone', 'internet', 'software', 'digital'],\n            'culture': ['culture', 'tradition', 'heritage', 'art', 'history'],\n            'war': ['war', 'battle', 'military', 'soldier', 'attack']\n        }\n        \n        print(\"✅ Ultra-simple models ready!\")\n    \n    def format_arabic_text(self, text):\n        \"\"\"Format Arabic text for proper display\"\"\"\n        try:\n            reshaped_text = arabic_reshaper.reshape(text)\n            return get_display(reshaped_text)\n        except:\n            return text\n    \n    def get_video_paths(self, data_dir=\"/kaggle/input\"):\n        \"\"\"Get video paths from Kaggle datasets\"\"\"\n        video_extensions = ['.mp4', '.avi', '.mov', '.mkv']\n        video_paths = []\n        \n        if os.path.exists(data_dir):\n            for root, dirs, files in os.walk(data_dir):\n                for file in files:\n                    if any(file.lower().endswith(ext) for ext in video_extensions):\n                        video_paths.append(os.path.join(root, file))\n        \n        return video_paths\n    \n    def list_available_videos(self):\n        \"\"\"List all available videos\"\"\"\n        video_paths = self.get_video_paths()\n        \n        if not video_paths:\n            print(\"📁 No video files found in /kaggle/input/\")\n            print(\"💡 Please add a dataset with video files\")\n            return []\n        \n        print(f\"🎬 Found {len(video_paths)} video files:\")\n        for i, path in enumerate(video_paths):\n            file_size = os.path.getsize(path) / (1024 * 1024)\n            print(f\"   {i+1}. {os.path.basename(path)} ({file_size:.1f} MB)\")\n        \n        return video_paths\n    \n    def extract_audio_ultra_simple(self, video_path):\n        \"\"\"Extract audio from video\"\"\"\n        try:\n            with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as temp_audio:\n                audio_path = temp_audio.name\n            \n            video = VideoFileClip(video_path)\n            video.audio.write_audiofile(audio_path, verbose=False, logger=None)\n            return audio_path\n        except Exception as e:\n            print(f\"❌ Error extracting audio: {e}\")\n            return None\n\n    def transcribe_audio_ultra_simple(self, audio_path):\n        \"\"\"Transcribe audio using Google Speech Recognition\"\"\"\n        try:\n            with sr.AudioFile(audio_path) as source:\n                audio = self.recognizer.record(source)\n            \n            # Try different languages\n            languages = ['ar-SA', 'fr-FR', 'en-US']\n            \n            for lang in languages:\n                try:\n                    text = self.recognizer.recognize_google(audio, language=lang)\n                    if len(text.strip()) > 2:\n                        lang_name = {'ar-SA': 'arabic', 'fr-FR': 'french', 'en-US': 'english'}[lang]\n                        return text, lang_name\n                except:\n                    continue\n            \n            # Final attempt without language\n            try:\n                text = self.recognizer.recognize_google(audio)\n                return text, \"auto-detected\"\n            except:\n                return \"No speech detected\", \"unknown\"\n                \n        except Exception as e:\n            print(f\"❌ Transcription error: {e}\")\n            return \"\", \"unknown\"\n\n    def detect_language_simple(self, text):\n        \"\"\"Simple language detection based on character analysis\"\"\"\n        if len(text.strip()) < 3:\n            return \"unknown\"\n        \n        # Check for Arabic characters\n        arabic_chars = set('ابتثجحخدذرزسشصضطظعغفقكلمنهوي')\n        if any(char in arabic_chars for char in text):\n            return \"arabic\"\n        \n        # Check for French accents\n        french_chars = set('éèêëàâäîïôöùûüç')\n        if any(char in french_chars for char in text.lower()):\n            return \"french\"\n        \n        # Default to English\n        return \"english\"\n\n    def translate_text_simple(self, text, source_lang):\n        \"\"\"Simple translation using deep-translator\"\"\"\n        if source_lang == 'english':\n            return text\n        \n        if len(text.strip()) < 2:\n            return text\n            \n        try:\n            lang_map = {'arabic': 'ar', 'french': 'fr'}\n            source_code = lang_map.get(source_lang, 'auto')\n            translated = GoogleTranslator(source=source_code, target='en').translate(text[:500])\n            return translated\n        except Exception as e:\n            print(f\"⚠️  Translation failed: {e}\")\n            return text\n\n    def analyze_emotions_simple(self, text):\n        \"\"\"Simple emotion analysis based on keywords\"\"\"\n        text_lower = text.lower()\n        \n        emotion_scores = {}\n        for emotion, keywords in self.emotion_keywords.items():\n            score = sum(1 for keyword in keywords if keyword in text_lower)\n            emotion_scores[emotion] = score\n        \n        if any(score > 0 for score in emotion_scores.values()):\n            dominant_emotion = max(emotion_scores, key=emotion_scores.get)\n            return dominant_emotion\n        else:\n            return \"neutral\"\n\n    def detect_faces_simple(self, video_path):\n        \"\"\"Simple face detection (presence/absence)\"\"\"\n        cap = cv2.VideoCapture(video_path)\n        face_detected = False\n        \n        # Check first 5 frames\n        for _ in range(5):\n            ret, frame = cap.read()\n            if ret:\n                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n                faces = self.face_cascade.detectMultiScale(gray, 1.1, 4)\n                if len(faces) > 0:\n                    face_detected = True\n                    break\n        \n        cap.release()\n        return \"faces_detected\" if face_detected else \"no_faces\"\n\n    def classify_topic_simple(self, text):\n        \"\"\"Simple topic classification based on keywords\"\"\"\n        text_lower = text.lower()\n        \n        topic_scores = {}\n        for topic, keywords in self.topic_keywords.items():\n            score = sum(1 for keyword in keywords if keyword in text_lower)\n            topic_scores[topic] = score\n        \n        if any(score > 0 for score in topic_scores.values()):\n            dominant_topic = max(topic_scores, key=topic_scores.get)\n            confidence = topic_scores[dominant_topic] / len(text.split()) * 10\n            confidence = min(confidence, 1.0)  # Cap at 1.0\n            return dominant_topic, confidence\n        else:\n            return \"general\", 0.3\n\n    def summarize_text_simple(self, text):\n        \"\"\"Simple text summarization\"\"\"\n        if len(text) < 30:\n            return \"Insufficient text for summary\"\n        \n        sentences = text.split('.')\n        if len(sentences) > 2:\n            # Take first and last sentence for summary\n            summary = sentences[0] + '. ' + sentences[-1] + '.'\n            return summary\n        else:\n            return text[:200] + \"...\"\n\n    def analyze_video_ultra_simple(self, video_path=None):\n        \"\"\"Ultra-simple main analysis function\"\"\"\n        if video_path is None:\n            video_paths = self.get_video_paths()\n            if not video_paths:\n                return {\"error\": \"No video files found in /kaggle/input/\"}\n            video_path = video_paths[0]\n        \n        print(f\"🎬 Analyzing: {os.path.basename(video_path)}\")\n        \n        # Get basic video info\n        cap = cv2.VideoCapture(video_path)\n        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n        fps = cap.get(cv2.CAP_PROP_FPS)\n        duration = total_frames / fps if fps > 0 else 0\n        cap.release()\n        \n        print(f\"📊 Video Info: {duration:.1f}s, {total_frames} frames\")\n        \n        # Step 1: Extract audio\n        print(\"🔊 Extracting audio...\")\n        audio_path = self.extract_audio_ultra_simple(video_path)\n        if not audio_path:\n            return {\"error\": \"Failed to extract audio\"}\n        \n        # Step 2: Transcribe audio\n        print(\"🗣️ Transcribing audio...\")\n        transcribed_text, detected_language = self.transcribe_audio_ultra_simple(audio_path)\n        \n        print(f\"📝 Transcribed text length: {len(transcribed_text)} characters\")\n        print(f\"🌐 Detected language: {detected_language}\")\n        \n        # Step 3: Language detection\n        final_language = self.detect_language_simple(transcribed_text)\n        print(f\"🔍 Confirmed language: {final_language}\")\n        \n        # Step 4: Translate if needed\n        if final_language != 'english':\n            english_text = self.translate_text_simple(transcribed_text, final_language)\n        else:\n            english_text = transcribed_text\n        \n        # Step 5: Analyze emotions\n        print(\"😊 Analyzing emotions...\")\n        text_emotion = self.analyze_emotions_simple(english_text)\n        face_status = self.detect_faces_simple(video_path)\n        \n        # Step 6: Classify topic\n        print(\"🏷️ Classifying topic...\")\n        main_topic, topic_confidence = self.classify_topic_simple(english_text)\n        \n        # Step 7: Generate summary\n        print(\"📄 Generating summary...\")\n        video_summary = self.summarize_text_simple(english_text)\n        \n        # Clean up\n        try:\n            if os.path.exists(audio_path):\n                os.unlink(audio_path)\n        except:\n            pass\n        \n        # Compile results\n        results = {\n            \"video_info\": {\n                \"file_name\": os.path.basename(video_path),\n                \"duration_seconds\": duration,\n                \"total_frames\": total_frames,\n                \"detected_language\": final_language,\n                \"transcribed_text_length\": len(transcribed_text)\n            },\n            \"analysis\": {\n                \"face_detection\": face_status,\n                \"text_emotion\": text_emotion,\n                \"main_topic\": main_topic,\n                \"topic_confidence\": f\"{topic_confidence:.1%}\",\n                \"video_summary\": video_summary\n            },\n            \"content\": {\n                \"original_transcription\": transcribed_text[:350] + \"...\" if len(transcribed_text) > 350 else transcribed_text,\n                \"english_translation\": english_text[:350] + \"...\" if len(english_text) > 350 else english_text\n            }\n        }\n        \n        return results\n    \n    def display_ultra_simple_results(self, results):\n        \"\"\"Display results in ultra-simple format\"\"\"\n        if \"error\" in results:\n            print(f\"❌ Error: {results['error']}\")\n            return\n        \n        print(\"\\n\" + \"=\"*60)\n        print(\"🎯 ULTRA-SIMPLE VIDEO ANALYSIS RESULTS\")\n        print(\"=\"*60)\n        \n        print(f\"\\n📁 VIDEO INFORMATION:\")\n        print(f\"   File: {results['video_info']['file_name']}\")\n        print(f\"   Duration: {results['video_info']['duration_seconds']:.1f} seconds\")\n        print(f\"   Language: {results['video_info']['detected_language']}\")\n        print(f\"   Transcription Length: {results['video_info']['transcribed_text_length']} chars\")\n        \n        print(f\"\\n📊 ANALYSIS RESULTS:\")\n        print(f\"   Face Detection: {results['analysis']['face_detection']}\")\n        print(f\"   Emotion: {results['analysis']['text_emotion']}\")\n        print(f\"   Main Topic: {results['analysis']['main_topic']}\")\n        print(f\"   Confidence: {results['analysis']['topic_confidence']}\")\n        \n        print(f\"\\n📄 VIDEO SUMMARY:\")\n        if results['video_info']['detected_language'] == 'arabic':\n            formatted_summary = self.format_arabic_text(results['analysis']['video_summary'])\n            print(f\"   {formatted_summary}\")\n        else:\n            print(f\"   {results['analysis']['video_summary']}\")\n        \n        print(f\"\\n🗣️ CONTENT PREVIEW:\")\n        original_text = results['content']['original_transcription']\n        if results['video_info']['detected_language'] == 'arabic':\n            formatted_original = self.format_arabic_text(original_text)\n            print(f\"   Original: {formatted_original}\")\n        else:\n            print(f\"   Original: {original_text}\")\n        \n        if results['content']['english_translation'] != original_text:\n            print(f\"   English: {results['content']['english_translation']}\")\n\n# Step 4: Main execution function\ndef run_ultra_simple_analysis():\n    \"\"\"Run ultra-simple analysis in Kaggle\"\"\"\n    print(\"🚀 Starting Ultra-Simple Video Analysis\")\n    print(\"=\"*50)\n    print(\"🌍 Supports: Arabic 🇸🇦 | French 🇫🇷 | English 🇺🇸\")\n    print(\"=\"*50)\n    \n    try:\n        analyzer = UltraSimpleVideoAnalyzer()\n        \n        # List available videos\n        video_paths = analyzer.list_available_videos()\n        if not video_paths:\n            return\n        \n        # Analyze first video\n        results = analyzer.analyze_video_ultra_simple()\n        \n        # Display results\n        analyzer.display_ultra_simple_results(results)\n        \n        # Save results\n        try:\n            output_file = \"ultra_simple_video_analysis.json\"\n            with open(output_file, 'w', encoding='utf-8') as f:\n                json.dump(results, f, ensure_ascii=False, indent=2)\n            print(f\"\\n💾 Results saved to: {output_file}\")\n        except Exception as e:\n            print(f\"⚠️  Could not save results: {e}\")\n            \n        return results\n        \n    except Exception as e:\n        print(f\"❌ Analysis failed: {e}\")\n        print(\"💡 This is a simplified version that should work in Kaggle\")\n\n# Run the analysis\nif __name__ == \"__main__\":\n    results = run_ultra_simple_analysis()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T09:43:41.064312Z","iopub.execute_input":"2025-12-03T09:43:41.064849Z","iopub.status.idle":"2025-12-03T09:44:03.551233Z","shell.execute_reply.started":"2025-12-03T09:43:41.064824Z","shell.execute_reply":"2025-12-03T09:44:03.550554Z"}},"outputs":[{"name":"stdout","text":"🚀 Starting Ultra-Simple Video Analysis\n==================================================\n🌍 Supports: Arabic 🇸🇦 | French 🇫🇷 | English 🇺🇸\n==================================================\n🔄 Setting up ultra-simple models...\n✅ Ultra-simple models ready!\n🎬 Found 3 video files:\n   1. ..          .mp4 (11.9 MB)\n   2. Wayne Rooney says Ruben Amorim and players must take responsibility for Man Utd form (1).mp4 (5.2 MB)\n   3. Hamas and Israel begin indirect talks to end devastating war in Gaza (1).mp4 (19.0 MB)\n🎬 Analyzing: ..          .mp4\n📊 Video Info: 171.3s, 4283 frames\n🔊 Extracting audio...\n🗣️ Transcribing audio...\n📝 Transcribed text length: 219 characters\n🌐 Detected language: arabic\n🔍 Confirmed language: arabic\n😊 Analyzing emotions...\n🏷️ Classifying topic...\n📄 Generating summary...\n\n============================================================\n🎯 ULTRA-SIMPLE VIDEO ANALYSIS RESULTS\n============================================================\n\n📁 VIDEO INFORMATION:\n   File: ..          .mp4\n   Duration: 171.3 seconds\n   Language: arabic\n   Transcription Length: 219 chars\n\n📊 ANALYSIS RESULTS:\n   Face Detection: faces_detected\n   Emotion: neutral\n   Main Topic: war\n   Confidence: 18.2%\n\n📄 VIDEO SUMMARY:\n   In the resistance operations, the Al-Qassam Brigades were deployed. .\n\n🗣️ CONTENT PREVIEW:\n   Original: ﻝﻮﺳﺮﻟﺍ ﺕﻮﺻ ﻖﻳﺮﻄﻟﺍ ﺍﺬﻫ ﻰﻠﻋ ﷲ ﻰﻠﺻ ﷲ ﺀﺎﺷ ﻥﺍ ﻞﺟﻭ ﺰﻋ ﷲ ﻥﺫﺎﺑ ﷲ ﺀﺎﺷ ﻥﺍ ﺪﺑﻼﻟ ﺏﻮﺘﻜﻣ ﻩﺰﻏ ﻪﻨﻳﺪﻣ ﻲﺑﻮﻨﺟ ﻯﻮﻬﻟﺍ ﻞﺗ ﻲﺤﺑ ﺕﺎﺒﻫﺍﺮﻟﺍ ﻪﺳﺭﺪﻣ ﻲﻓ ﻪﻴﻠﻴﺋﺍﺮﺳﺍ ﺕﺎﻴﻟﺍﻭ ﺩﻮﻨﺠﻟ ﻊﻤﺠﺘﻟﺍ ﺎﻬﻓﺍﺪﻬﺘﺳﺍ ﻦﻣ ﺪﻬﺷ ﻡﺎﺴﻘﻟﺍ ﺐﺋﺎﺘﻛ ﺕﺮﺸﻧ ﻪﻣﻭﺎﻘﻤﻟﺍ ﺕﺎﻴﻠﻤﻋ ﻲﻓﻭ\n   English: In the resistance operations, the Al-Qassam Brigades were deployed. Evidence of their targeting of a gathering of Israeli soldiers and vehicles at the nuns’ school in the Tal Al-Hawa neighborhood, south of Gaza City, is written forever, God willing, God willing, God Almighty, God willing, may God bless this path, the voice of the Messenger.\n\n💾 Results saved to: ultra_simple_video_analysis.json\n","output_type":"stream"}],"execution_count":6}]}